{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (3i026) -- 2018-2019\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Manon Ansart, Vincent Guigue, Marie-Jeanne Lesot, Christophe Marsala, Olivier Schwander.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME03: programmation du perceptron\n",
    "\n",
    "Dans ce TP, nous allons principalement programmer un perceptron, en nous restreignant au cas binaire où les données sont étiquetées $+1$ ou $-1$ (comme les séances précédentes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jouve Vincent et Cadiou Antoine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-03</tt> et rajouter à la suite de <tt>tme-03</tt> les noms des membres du binômes séparés par un tiret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-03-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">** à la fin de la séance**</font>. C'est ce compte-rendu qui donne la note de base de la séance.\n",
    "- vous pouvez éventuellement compléter votre compte-rendu  pour obtenir des points bonus, dans ce cas, vous devez soumettre votre complément avant le début de la semaine suivante.\n",
    "\n",
    "** Sur la page Moodle de remise du travail <font color=\"RED\">ne pas oublier d'envoyer le compte rendu</font>** à la fin de la séance, la soumission de la version complémentaire post-séance se fera sur une page différente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'une librairie\n",
    "\n",
    "Afin de pouvoir réutiliser les classes et fonctions écrites dans les séances de TDTME précédentes, on va construire une librairie qu'il suffira d'importer.\n",
    "\n",
    "Récupérer l'archive iads.tgz et la désarchiver de telle sorte que le répertoire iads soit un répertoire frère du répertoire tme03.\n",
    "\n",
    "Ainsi, vous devrez avoir l'arborescence suivante dans votre répertoire $HOME:\n",
    "\n",
    "    - 3i026/\n",
    "        - tme01/\n",
    "            - tme01.ipynb\n",
    "        - tme02/\n",
    "            - tme02.ipynb\n",
    "        - tme03/\n",
    "            - tme03.ipynb\n",
    "        - iads/\n",
    "            - Classifiers.py\n",
    "            - LabeledSet.py\n",
    "            - utils.py\n",
    "          \n",
    "\n",
    "**Important** :\n",
    "- ce fichier tme03.ipynb doit toujours rester dans le répertorie tme03/\n",
    "- pour ouvrir les fichiers py qui se trouvent dans le répertoire iads/ il est nécessaire d'utiliser un éditeur de texte comme emacs, gedit, idle,...\n",
    "\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Ouvrir et compléter les fichiers Classifiers.py et utils.py**\n",
    "\n",
    "Pour compléter ces fichiers, reprendre le code écrit dans le TDTME précédent pour compléter toute les parties indiquées <tt>#TODO</tt>.\n",
    "- dans utils.py, il faut compléter la fonction createGaussianDataset\n",
    "- dans Classifiers.py, il faut compléter le code des classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois ces fichiers complétés, la librairie <tt>iads</tt> peut être importée dans ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a005a9ac96e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Importation de la librairie iads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0miads\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0miads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# importation de LabeledSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iads'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de LabeledSet\n",
    "from iads import LabeledSet as ls\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as cl\n",
    "\n",
    "# importation de utils\n",
    "# from iads import utils_iads as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande <tt>help</tt> permet d'avoir des informations sur le contenu d'une librairie importée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(iads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les boîtes suivantes, on utilise ces librairies avec les exemples vus en TDTME-02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de LabeledSet\n",
    "\n",
    "une_base = ls.LabeledSet(2)        # définition d'une base pour contenir des exemples en 2D\n",
    "\n",
    "une_base.addExample([0, 1],1)   # ajout de l'exemple (0, 1) de classe +1\n",
    "une_base.addExample([2, 3],1)   # ajout de l'exemple (2, 3) de classe +1\n",
    "une_base.addExample([1, 2],-1)  # ajout de l'exemple (1, 2) de classe -1\n",
    "une_base.addExample([2, 2],-1)  # ajout de l'exemple (2, 2) de classe -1\n",
    "\n",
    "# Fonction pour afficher le LabeledSet\n",
    "def affiche_base(LS):\n",
    "    \"\"\" LabeledSet\n",
    "        affiche le contenu de LS\n",
    "    \"\"\"\n",
    "    for i in range(0,LS.size()):\n",
    "        print(\"Exemple \"+str(i))\n",
    "        print(\"\\tdescription : \",LS.getX(i))\n",
    "        print(\"\\tlabel : \",LS.getY(i))\n",
    "    return\n",
    "\n",
    "# Affichage de la base\n",
    "affiche_base(une_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2DSet(set):\n",
    "    \"\"\" LabeledSet -> NoneType\n",
    "        Hypothèse: set est de dimension 2\n",
    "        affiche une représentation graphique du LabeledSet\n",
    "        remarque: l'ordre des labels dans set peut être quelconque\n",
    "    \"\"\"\n",
    "    S_pos = set.x[np.where(set.y == 1),:][0]      # tous les exemples de label +1\n",
    "    S_neg = set.x[np.where(set.y == -1),:][0]     # tous les exemples de label -1\n",
    "    plt.scatter(S_pos[:,0],S_pos[:,1],marker='o') # 'o' pour la classe +1\n",
    "    plt.scatter(S_neg[:,0],S_neg[:,1],marker='x') # 'x' pour la classe -1\n",
    "\n",
    "def plot_frontiere(set,classifier,step=10):\n",
    "    \"\"\" LabeledSet * Classifier * int -> NoneType\n",
    "        Remarque: le 3e argument est optionnel et donne la \"résolution\" du tracé\n",
    "        affiche la frontière de décision associée au classifieur\n",
    "    \"\"\"\n",
    "    mmax=set.x.max(0)\n",
    "    mmin=set.x.min(0)\n",
    "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
    "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
    "    \n",
    "    # calcul de la prediction pour chaque point de la grille\n",
    "    res=np.array([classifier.predict(grid[i,:]) for i in range(len(grid)) ])\n",
    "    res=res.reshape(x1grid.shape)\n",
    "    # tracer des frontieres\n",
    "    plt.contourf(x1grid,x2grid,res,colors=[\"red\",\"cyan\"],levels=[-1000,0,1000])\n",
    "    \n",
    "# ------------------------ \n",
    "\n",
    "def createGaussianDataset(positive_center, positive_sigma, negative_center, negative_sigma, nb_points):\n",
    "    \"\"\" \n",
    "        rend un LabeledSet 2D généré aléatoirement.\n",
    "        Arguments:\n",
    "        - positive_center (vecteur taille 2): centre de la gaussienne des points positifs\n",
    "        - positive_sigma (matrice 2*2): variance de la gaussienne des points positifs\n",
    "        - negative_center (vecteur taille 2): centre de la gaussienne des points négative\n",
    "        - negative_sigma (matrice 2*2): variance de la gaussienne des points négative\n",
    "        - nb_points (int):  nombre de points de chaque classe à générer\n",
    "    \"\"\"\n",
    "    labeledSet = ls.LabeledSet(2)\n",
    "    for i in range(0, nb_points):\n",
    "        pos = np.random.multivariate_normal(positive_center,positive_sigma)\n",
    "        neg = np.random.multivariate_normal(negative_center,negative_sigma)\n",
    "        labeledSet.addExample(pos,1)\n",
    "        labeledSet.addExample(neg,-1)\n",
    "    return labeledSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de utils\n",
    "\n",
    "the_set = createGaussianDataset(np.array([1,1]),np.array([[1,0],[0,1]]),np.array([-1,-1]),np.array([[1,0],[0,1]]),10)\n",
    "the_set100 = createGaussianDataset(np.array([1,1]),np.array([[1,0],[0,1]]),np.array([-1,-1]),np.array([[1,0],[0,1]]),100)\n",
    "\n",
    "print(\"Taille de la base jouet générée :\", the_set.size(), \"exemples\")\n",
    "\n",
    "# Affichage :\n",
    "plot2DSet(the_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de Classifiers pour créer un knn:\n",
    "\n",
    "knn = cl.ClassifierKNN(2,3)\n",
    "\n",
    "knn.train(the_set)\n",
    "\n",
    "plot_frontiere(the_set,knn)\n",
    "plot2DSet(the_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+2\">**Très important**</font>: tout le reste du travail à faire dans ce TDTME ne doit être fait que dans le notebook. Il ne faut plus modifier les fichiers de la librairie.\n",
    "\n",
    "Le compte-rendu de cette séance ne comportera que le fichier notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron aléatoire\n",
    "====\n",
    "\n",
    "La classe <tt>ClassifierPerceptronRandom</tt> suivante hérite de la classe `Classifier`. Elle implémente un modèle de perceptron aléatoire qui modélise un hyperplan $f_w(x)=\\langle w ; x \\rangle$ tel que $w$ est tiré aléatoirement lors de la création.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierPerceptronRandom(cl.Classifier):\n",
    "    def __init__(self, input_dimension):\n",
    "        \"\"\" Argument:\n",
    "                - input_dimension (int) : dimension d'entrée des exemples\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        v = np.random.rand(input_dimension)     # vecteur aléatoire à input_dimension dimensions\n",
    "        self.w = (2* v - 1) / np.linalg.norm(v) # on normalise par la norme de v\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\" rend la prediction sur x (-1 ou +1)\n",
    "        \"\"\"\n",
    "        z = np.dot(x, self.w)\n",
    "        return z\n",
    "        \n",
    "    def train(self,labeledSet):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "        \"\"\"        \n",
    "        print(\"No training needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Tester ce modèle de perceptron sur un jeu de données aléatoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de création et d'utilisation d'un Perceptron aléatoire:\n",
    "\n",
    "perceptron_random = ClassifierPerceptronRandom(2)\n",
    "\n",
    "plot_frontiere(the_set,perceptron_random)\n",
    "plot2DSet(the_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron de Rosenblatt\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> En héritant de la classe `Classifier`, écrire la classe <tt>ClassifierPerceptron</tt> qui implémente l'algorithme du Perceptron de Rosenblatt vu en cours.\n",
    "\n",
    "La fonction `train` fera une itération sur l'ensemble des données de l'apprentissage. Les points d'apprentissage seront tirés dans un ordre aléatoire.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierPerceptron(cl.Classifier):\n",
    "    \"\"\" Perceptron de Rosenblatt\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dimension,learning_rate):\n",
    "        \"\"\" Argument:\n",
    "                - intput_dimension (int) : dimension d'entrée des exemples\n",
    "                - learning_rate :\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.dim = input_dimension\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w = np.array([0]*self.dim)\n",
    "\n",
    "    def predict(self,x):\n",
    "        \"\"\" rend la prediction sur x (-1 ou +1)\n",
    "        \"\"\"\n",
    "        z = np.dot(x, self.w)\n",
    "        return z\n",
    "\n",
    "    \n",
    "    def train(self,labeledSet):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "        \"\"\"\n",
    "        tab = ([k for k in range(labeledSet.size())])\n",
    "        random.shuffle(tab)\n",
    "        for i in tab:\n",
    "            x = labeledSet.getX(i)\n",
    "            y = labeledSet.getY(i)\n",
    "            if (self.predict(x)*y <= 0):\n",
    "                self.w = self.w + self.learning_rate*(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = ClassifierPerceptron(2, 0.1)\n",
    "perceptron.train(the_set)\n",
    "\n",
    "plot_frontiere(the_set, perceptron)\n",
    "plot2DSet(the_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Tester le perceptron de la manière suivante:\n",
    "- Apprendre pendant N itérations\n",
    "- Afficher l'accuracy du modèle à chaque itération\n",
    "- Vérifier que l'accuracy baisse\n",
    "- Dessiner la frontière obtenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "perceptron = ClassifierPerceptron(2, 1)\n",
    "accuracies=[]\n",
    "for i in range (N):\n",
    "    perceptron.train(the_set)\n",
    "    accuracies.append(perceptron.accuracy(the_set))\n",
    "plt.ylim(0.5,1)\n",
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "perceptron = ClassifierPerceptron(2, 0.1)\n",
    "accuracies=[]\n",
    "for i in range (N):\n",
    "    perceptron.train(the_set100)\n",
    "    accuracies.append(perceptron.accuracy(the_set100))\n",
    "plt.ylim(0.5,1)\n",
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "for epsilon in [1/(10**n) for n in range(1, 5)]:\n",
    "    perceptron = ClassifierPerceptron(2, epsilon)\n",
    "    accuracies=[]\n",
    "    for i in range (N):\n",
    "        perceptron.train(the_set100)\n",
    "        accuracies.append(perceptron.accuracy(the_set100))\n",
    "    print(\"epsilon=\",epsilon)\n",
    "    plt.plot(accuracies)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courbe 1 : On observe qu'il y a beaucuoup de variations de la précision du classifieur, c'est dû au taux d'apprentissage qui est trop grand (donc w varie trop brutalement).\n",
    "\n",
    "Courbe 2: même observation que la courbe 1 mais il y a moins d'amplitude dans les précisions\n",
    "\n",
    "Courbe 3: on a convergé vers une précision constante, ce qui fait que ce taux d'apprentissage, pour ce jeu de données et le nombre de fois où on a appris (N) est cohérent\n",
    "\n",
    "Courbe 4: Le taux d'apprentissage est trop petit donc w varie trop lentement pour notre nombre (N) d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Expérimentations\n",
    "\n",
    "- Générer deux ensembles de train et de test\n",
    "- Dessiner la courbe de performance en fonction de l'itération sur les ensembles de train et de test\n",
    "    * Que se passe-t-il en fonction du pas (epsilon) d'apprentissage ? \n",
    "    * Que se passe-t-il quand le nombre d'exemples en apprentissage est faible ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = createGaussianDataset(np.array([1,1]),np.array([[1,0],[0,1]]),np.array([-1,-1]),np.array([[1,0],[0,1]]),100)\n",
    "test = createGaussianDataset(np.array([1,1]),np.array([[1,0],[0,1]]),np.array([-1,-1]),np.array([[1,0],[0,1]]),100)\n",
    "\n",
    "N = 100\n",
    "for epsilon in [1/(10**n) for n in range(1, 5)]:\n",
    "    perceptron = ClassifierPerceptron(2, epsilon)\n",
    "    accuracies=[]\n",
    "    for i in range (N):\n",
    "        perceptron.train(train)\n",
    "        accuracies.append(perceptron.accuracy(test))\n",
    "    print(\"epsilon=\",epsilon)\n",
    "    plt.plot(accuracies)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Données XOR**\n",
    "\n",
    "Ecrire la fpnction `createXOR` qui, étant donné un nombre de points $n$ et une variance $var$, permet de générer une base de données contenant:\n",
    "- deux gaussiennes centrées en (0,0) et (1,1) correspondant à $n$ exemples positifs\n",
    "- deux gaussiennes centrées en (1,0) et (0,1) correspondant à $n$ exemples négatifs\n",
    "\n",
    "Dans la suite, on appelle XOR une base de données créée par cette fonction.\n",
    "\n",
    "\n",
    "Que se passe-t-il quand on apprend un perceptron  ? Quel est le problème ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXOR(n, var):\n",
    "    labeledSet = ls.LabeledSet(2)\n",
    "    for i in range(0, n):\n",
    "        labeledSet.addExample(np.random.multivariate_normal([0,0],[[var,0],[0,var]]),1)\n",
    "        labeledSet.addExample(np.random.multivariate_normal([1,1],[[var,0],[0,var]]),1)\n",
    "        labeledSet.addExample(np.random.multivariate_normal([1,0],[[var,0],[0,var]]),-1)\n",
    "        labeledSet.addExample(np.random.multivariate_normal([0,1],[[var,0],[0,var]]),-1)\n",
    "    return labeledSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor=createXOR(100,0.01)\n",
    "plot2DSet(xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "perceptronXor = ClassifierPerceptron(2, 0.001)\n",
    "accuracies=[]\n",
    "for i in range (N):\n",
    "    perceptronXor.train(xor)\n",
    "    accuracies.append(perceptronXor.accuracy(xor))\n",
    "plt.ylim(0,1)\n",
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on observe que la précision tourne autour de 0.5 ce qui est normal car on ne peut pas tracer une droite qui passe par l'origine est qui sépare bien nos classe de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Trick\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons projeter (manuellement) les données 2D dans un espace de plus grande dimension. Voici un exemple de projection qui transforme un vecteur $(x_1,x_2)$ en un vecteur $(x_1,x_2,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelBias:\n",
    "    def transform(self,x):\n",
    "        y=np.asarray([x[0],x[1],1])\n",
    "        return y\n",
    "\n",
    "k=KernelBias()\n",
    "k.transform(the_set.getX(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter la classe ClassifierPerceptronKernel qui prend un Kernel en paramètre, et calcule le perceptron sur la version \"kernélisée\" des données. Tester ce perceptron sur le dataset 1 (2 gaussiennes) et le dataset XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c098cbea7e83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mClassifierPerceptronKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimension_kernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \"\"\" Argument:\n\u001b[0;32m      4\u001b[0m                 \u001b[1;33m-\u001b[0m \u001b[0mintput_dimension\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdimension\u001b[0m \u001b[0md\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mentrée\u001b[0m \u001b[0mdes\u001b[0m \u001b[0mexemples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[1;33m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cl' is not defined"
     ]
    }
   ],
   "source": [
    "class ClassifierPerceptronKernel(cl.Classifier):\n",
    "    def __init__(self,dimension_kernel,learning_rate,kernel):\n",
    "        \"\"\" Argument:\n",
    "                - intput_dimension (int) : dimension d'entrée des exemples\n",
    "                - learning_rate :\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.dim = dimension_kernel\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kernel=kernel\n",
    "        self.w = np.array([0]*self.dim)\n",
    "\n",
    "    def predict(self,x):\n",
    "        \"\"\" rend la prediction sur x (-1 ou +1)\n",
    "        \"\"\"\n",
    "        xtrans = self.kernel.transform(x)\n",
    "        z = np.dot(xtrans, self.w)\n",
    "        return z\n",
    "\n",
    "    \n",
    "    def train(self,labeledSet):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "        \"\"\"\n",
    "        tab = ([k for k in range(labeledSet.size())])\n",
    "        random.shuffle(tab)\n",
    "        for i in tab:\n",
    "            x = labeledSet.getX(i)\n",
    "            xtrans = self.kernel.transform(x)\n",
    "            y = labeledSet.getY(i)\n",
    "            if (self.predict(x)*y <= 0):\n",
    "                self.w = self.w + self.learning_rate*(xtrans * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "setKernel=createGaussianDataset(np.array([2,2]),np.array([[1,0],[0,1]]),np.array([4,4]),np.array([[1,0],[0,1]]),100)\n",
    "perceptronKernel = ClassifierPerceptronKernel(3, 0.001, k)\n",
    "for i in range (N):\n",
    "    perceptronKernel.train(setKernel)\n",
    "plot_frontiere(setKernel, perceptronKernel)\n",
    "plot2DSet(setKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "perceptronXorKernel = ClassifierPerceptronKernel(3, 0.01,k)\n",
    "for i in range (N):\n",
    "    perceptronXorKernel.train(xor)\n",
    "plot_frontiere(xor, perceptronXorKernel)\n",
    "plot2DSet(xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter le kernel : $(x_1,x_2) \\rightarrow (1,x_1,x_2,x_1*x_1,x_2*x_2,x_1*x_2)$. Entrainer le perceptron correspondant sur le XOR. Que constatez-vous ? Donnez une explication (explication donnée en cours lors de la prochaine séance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPoly:\n",
    "    def transform(self,x):\n",
    "        y=np.asarray([1, x[0], x[1], x[0]*x[0], x[1]*x[1], x[0]*x[1]])\n",
    "        return y\n",
    "\n",
    "N=100\n",
    "k2=KernelPoly()\n",
    "perceptron_k = ClassifierPerceptronKernel(6, 0.001, k2)\n",
    "\n",
    "for i in range (N):\n",
    "    perceptron_k.train(xor)\n",
    "plot_frontiere(xor, perceptron_k)\n",
    "plot2DSet(xor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expérimentations sur des datasets réels\n",
    "-------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A partir de datasets trouvés sur le web, réaliser un ensemble d'expérimentations permettant de comparer les 3 classifiers (knn, perceptron de Rosenblatt et version kernélisée) que vous avez implémentés.\n",
    "\n",
    "Par exemple, vous pouvez utiliser les datasets suivants:\n",
    "- https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra\n",
    "- https://www.kaggle.com/uciml/indian-liver-patient-records\n",
    "- voir sur les données ouvertes de Paris : https://opendata.paris.fr/explore/?sort=modified\n",
    "\n",
    "Afin d'utiliser de tels jeux de données, il sera certainement nécessaire que vous réalisiez un prétraitement afin de pouvoir utiliser vos implémentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
